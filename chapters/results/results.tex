\chapter{Results}
\label{chap:Results}

After application of all cuts to the analysis data set one event from July 2012 passes through it's vertically polarised (VPol) antenna's waveforms. When this event is compared to the expected number of background events it is not considered to be a statistically significant observation of a flux of UHE neutrinos, hence a model independent limit can be calculated. Before doing so the passing event will be described and a comparison drawn with expectations of a neutrino induced signal.



\section{Candidate neutrino event}
\label{sec:Results:Neutrino-Candidate}

A single event, number 13590 from run 21609, survives the analysis cuts. The coherently summed wave (CSW) and pseudo-$\chi^{2}$ map are shown in \FigureRef{fig:Results:CSW-ChiSq} and individual VPol antenna waveforms in \FigureRef{fig:Results:Waveforms}. The individual waveforms and the resulting CSW are not consistent with expectations of neutrino induced signals, showing no impulsive signal characteristic of such events. Six other events with similar waveforms were found in the same run but were rejected as they failed a combination of the reconstruction (pseudo-$\chi^{2}$ and geometry cuts) and CW cuts, therefore it is infered that this event is from an unidentified background source. 

\begin{figure}
  \subfloat[CSW VPol]{\includegraphics[width=0.48\textwidth]{chapters/results/candidateCSWVPol.pdf}}\hfill
  \subfloat[Pseudo-$\chi^{2}$ map VPol]{\includegraphics[width=0.48\textwidth]{chapters/results/candidateChiSqVPol.pdf}}
  \caption{CSW and pseudo-$\chi^{2}$ map for the one survived VPol candidate event in 2012.}
  \label{fig:Results:CSW-ChiSq}
\end{figure}


\begin{figure}
  \subfloat[Antenna 1]{\includegraphics[width=0.48\textwidth]{chapters/results/candidateVPolAnt1.pdf}}\hfill
  \subfloat[Antenna 2]{\includegraphics[width=0.48\textwidth]{chapters/results/candidateVPolAnt2.pdf}}\\
  \subfloat[Antenna 3]{\includegraphics[width=0.48\textwidth]{chapters/results/candidateVPolAnt3.pdf}}\hfill
  \subfloat[Antenna 4]{\includegraphics[width=0.48\textwidth]{chapters/results/candidateVPolAnt4.pdf}}\
  \caption{Individual waveforms from the one survived VPol candidate event in 2012. There is a clear excess of power in the first two antennas not present in the others.}
  \label{fig:Results:Waveforms}
\end{figure}


The event has large correlated signals present in only two of the four VPol antennas which dominate the poweherence parameter, described in \SectionRef{sec:Analysis:Thermal-Cuts:Powherence}, used to distinguish between thermal and non-thermal signals. The reconstruction relies upon having coherent signals in all four antennas used to form the CSW, which is clearly not the case for this event. Such events could be removed from the analysis sample by making one or a number of cuts requiring all four antennas to have a minimum level of signal or coherence with the CSW. In addition this event narrowly passes the CW minProb cut described in \SectionRef{sec:Analysis:CWRemoval:CW-Identification} due to the presence of two large frequency narrow band signals in two of the antennas. The CW cut parameter $\ln (\prod P_{i})$ is shown in \FigureRef{fig:Results:minProb} along with the threshold minProb which is used to reject strong CW events.


\begin{figure}
  \includegraphics[width=\largefigwidth]{chapters/results/candidateMinProbVPol.pdf}
  \caption{CW parameter $\ln (\prod P_{i})$ is shown as a function of frequency for the VPol antennas in the one survived event. The regions filled with red correspond to frequencies that are considered to have measured amplitudes well in excess of expected thermal noise levels. The largest excess, corresponding to the most negative value of $\ln (\prod P_{i})$, comes very close to the CW minProb cut threshold (the upper of the two dashed lines).}
  \label{fig:Results:minProb}
\end{figure}


Although the survived event is clearly not a neutrino candidate it did pass all analysis cuts, so it will be considered as an observed event for limit setting purposes, a conservative approach since the resulting limit will be significantly weaker than with no events passing. 


\section{Live Time}
\label{sec:Results:Live-Time}

In order to calculate the sensitivity to a neutrino flux the integrated live time for the analysis data set must be calculated. Due to limitations in the TestBed electronics there is a period after a trigger is asserted, and event readout initiated, for which it is not possible to form another trigger. If a neutrino induced signal were to arrive at the TestBed during such a period the system would have no sensitivity to it as it would be unable to record it. The TestBed electronics monitors these periods and the associated `dead-time' via a $10 \mega \hertz$ clock. The dead-time is calculated by taking the number of clock cylces for which the trigger is unavailable in each GPS second, which can be scaled by the clock frequency to recover the fractional dead-time for each second of operation. The total live time for the analysis data set can then be calculated by taking the difference between the number of GPS seconds for which the TestBed operated and the sum of independent dead times recorded. 

Having obtained an integrated live time for the entire analysis data set a final adjustment must be made to take into account the good times cut described in \SectionRef{sec:Analysis:Anthropogenic-Cuts:Good-Times} and periods for which a significant fraction of events are rejected due to data quality issues. The good times cut masks off periods of the year that are associated with elevated levels of human activity and non-thermal events passing analysis cuts. All runs that are masked off by this cut have their integrated live time removed from the final live time measurement. Similarly any days of the year that have a sizeable fraction of events suffering from data quality issues have their integrated live time removed from the total. The fractional live time during each day of the year, as well as the resulting integrated live time are shown in \FigureRef{fig:Results:Integrated-LiveTime}. 

\begin{figure}
  \subfloat[Live time for 2011]{\includegraphics[width=0.48\textwidth]{chapters/results/LiveTime2011.pdf}}\hfill
  \subfloat[Live time for 2012]{\includegraphics[width=0.48\textwidth]{chapters/results/LiveTime2012.pdf}}\\
  \subfloat[Live time for 2011]{\includegraphics[width=0.48\textwidth]{chapters/results/FractionalLiveTime2011.pdf}}\hfill
  \subfloat[Live time for 2012]{\includegraphics[width=0.48\textwidth]{chapters/results/FractionalLiveTime2012.pdf}}
  \caption{Integrated live time for 2011 and 2012. Three lines are shown for each year: live time for all runs, live time for all runs with the majority of events passing data quality checks and finally live time for all runs passing both data quality and good times criteria. Fractional live time is also shown for all runs (red) and for those passing data quality and good times criteria (shaded magenta).}
  \label{fig:Results:Integrated-LiveTime}
\end{figure}

After accounting for data quality issues and applying the good times criteria the integrated live time is 162.8 days for 2011 and 43.3 days for 2012. The resulting live time for the full analysis data set is calculated to be 206.0 days.


\section{Effective area}
\label{sec:Results:Effective-Area}

The effective area is calculated for the TestBed from simulated neutrino data sets produced using AraSim as follows. Firstly the effective volume, $V_{eff}$, is calculated for each energy bin using a large sample of simulated events ($\sim 10^{6}$):

\begin{equation}
  V_{eff} = \frac {V_{cylinder}}{N} \sum_{i=1}^{N_{passed}} w_{i}
\end{equation}

\noindent where $V_{cylinder}$ is the volume of a cylinder centered on the detector in which events are simulated, $N$ is the total number of events thrown and $\sum_{i=1}^{N_{passed}} w_{i}$ is the sum of weights for triggered events. The effective volume is then converted into an effective area, $A_{eff}$, by using the approximation:

\begin{equation}
  A_{eff} \approx \frac{V_{eff}}{l_{int}}
\end{equation}

\noindent where $l_{int}$ is the neutrino interaction length in ice. 

\section{Neutrino flux limit}
\label{sec:Results:Limit}

An upper limit can be placed on the neutrino flux using the following equation:

\begin{equation}
  E_{\Pnu} \frac {dN}{dE_{\Pnu}} \leq \frac{N_{90}}{4\pi A_{eff}(E_{\Pnu}) T_{live} \varepsilon(E_{\Pnu}) \ln(10)}
\end{equation}

\noindent where $T_{live}$ is the total live time of the TestBed analysis data set, $\varepsilon(E_{\Pnu})$ is the energy dependant analysis efficiency, $N_{90}$ is the $90\%$ upper confidence limit on the number of neutrino events excluded by the analysis and the factor $\ln(10)$ accounts for log-scale energy binning. The live time and effective area are calculated as discussed in \SectionRef{sec:Results:Live-Time} and \SectionRef{sec:Results:Effective-Area}, and the analysis efficiency taken from application of cuts to simulated neutrino events shown in \FigureRef{fig:Analysis:Cut-Results:Efficiency}. Feldman Cousin's statistics are used to calculate $N_{90}$, with the single observed event on a background of $0.38^{+0.89}_{-0.38}$ yielding the $90\%$ upper bound of excluded events being $N_{90}=3.98$.

\begin{figure}[htpb]
  \includegraphics[width=\hugefigwidth]{chapters/results/LimitPlotr2801.pdf}
  \caption{TestBed analysis neutrino flux limit from this analysis `UCL 206', along with limits from ANITA \cite{PhysRevD.82.022004}, Auger \cite{Abraham:2009eh}, RICE \cite{PhysRevD.73.082002} and IceCube (citation needed). The shaded band indicates a range of flux predictions from \cite{Kotera.2010} using a variety of assumptions about sources and production mechanisms.}
  \label{fig:Results:Limit-Plot}
\end{figure}

The resulting UHE neutrino flux limit is shown in \FigureRef{fig:Results:Limit-Plot} along with limits from other experiments and a range of theoretical predicitons. The limit placed using this analysis is a factor $1.73$ weaker than if the final passing event were rejected as a neutrino candidate, however as the analysis does not place strict requirments on signal shape, which would lead to a reduction in efficiency, the displayed limit is a fairer representation of the conclusions drawn.

In addition to the limit calculated from this analysis of two years of TestBed data a projected sensitivity is shown for ARA-37 using a dedicated simulation. A number of factors lead to the much improved sensitivity reached by the full array. First and foremost is the increase in number of stations from one to thirty seven, each acting as a stand-alone neutrino detector, operated over a longer period. Deployment of stations at $\sim 200 \meter$ depths has been demonstrated over the 2012-2013 season and all further stations are expected to deployed at similar depths. By placing the antennas well below the firn layer of ice (which extends $\sim 150 \meter$ below the surface in the vicinity of the south pole), in which the changing index of refraction leads to ray-bending and shadowing effects, an increase in effective volume and area per station of the order $\sim 3$ over the TestBed is expected.

The expected level of anthroprogenic backgrounds is also expected to reduce greatly as the vast majority of future stations will be much further from the south pole station and human activity. In addition the receive antennas being placed much deeper in the ice will lead to a reduction in the signal size of above ice noise sources in each station. As well as the reduction in signal size the increased number of receive antennas, from four per polarisation to eight, is expected to significantly improve background identification and rejection. Anthroprogenic signal removal via masking off noisy periods of time, which is performed via the good times cut described in \SectionRef{sec:Analysis:Anthropogenic-Cuts:Good-Times}, leads to large periods of time being removed from the analysis sample and greatly reduces the total detector live time in this analysis. The expected reduction in number anthroprogenic signals associated with location will be complemented with better charecterisation of such signals and removal as the radio environment becomes better understood.

The re-designed data acquistion electronics and software (DAQ) will also lead to improvements in sensitivity. The updated DAQ allows for triggered event buffering such that the expected dead time associated with event readout described in \SectionRef{sec:Results:Live-Time} will be effectively nill. Improved 







