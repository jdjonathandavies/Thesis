\chapter{Analysis}
\label{chap:Analysis}

During the course of 2011 and 2012 the TestBed recorded around 480 million events and, given the relative size and operating time of the TestBed, it is expected that very few if any of these will contain signals produced by neutrino interactions in the ice. The overwhelming majority of these events contain signals that are backfrounds either triggered by thermal noise fluctuations or by anthroprogenic noise sources. These two categories of events have very different properties so an analysis approach is taken that aims to remove them in two stages. The first stage is to remove thermal noise events by requiring coherence between signals in multiple antennas consistent with a common physical source location. Due to the random nature of thermal events it is possible to use reconstruction and coherence tests to remove them from the data set, leaving only directional events. The majority of the remaining events are expected to be of anthroprogenic origin associated with infrastructure and human activity around the south pole station. These signals are likely to exhibit both spatial and temporal correlations not expected from a sample of neutrino events. Therefore it is possible to remove such anthroprogenic signals by rejecting reconstructed source locations associated with infrastructure or repeated signals and finally by removing events from time periods associated with high levels of human activity.

The TestBed records waveforms from both vertically polarised (VPol) and horizontally polarised (HPol) antennas for each event and these polarisations are treated seperately in analysis. This is in part due to the differences in signal chain and hence noise levels between the two. In addition it is expected that the majority of anthroprogenic signals will be limited to a single polarisation. Once intial data-quality checks have been applied to the events they are split into two `half events', one comprising of the signals in the VPol antennas and the other similarly from HPol antennas, that are propofated through the remaining cuts in order to asses whether or not they are to be considered a neutrino event.


\section{Blinding}
\label{sec:Analysis:Blinding}
The TestBed operated with very little downtime for the duration of 2011 and 2012 with the full data set archived to disk at the south pole. A limited bandwidth satellite link was available to transfer approximately $10 \%$ of this data back to the northern hemispere data warehouse with a latency of a few days. This `filtered' data set, which was randomly chosen, was used to asses operation and conditions in the TestBed such that significant data quality and downtime issues could be addressed during the winter season. The disks containing the full data set from 2011 and 2012 were hand carried back to the northern hemisphere during the 2011-2012 and 2012-2013 summer seasons and subsequently stored in the data warehouse, hosted at the University of Wisconsin. This analysis is based on that data set.

A blinding strategy was agreed by the experiment to limit any bias in analyses performed on the data. This was implemented by splitting the analysis data set into to two samples: a `burn sample' intended to be used for training the analysis and associated cuts, and a '$90 \% sample$` containing the remaining events. Once the experiment was in agreement with the methods, tools and cuts implemented on the `burn sample' of data the analysis was unblinded and run over the `$90 \%$ sample', with any events passing the cuts considered as neutrino candidates.

\section{Data types}
\label{sec:Analysis:Data-types}

There are three types of event recorded and made available for analysis:

\begin{itemize}

\item RF triggered events - events in which the trigger condition is met requiring 3 of 16 antennas to have passed a power threshold within a 100ns window.
\item Minimum bias events - recorded at a rate of $0.5 \hertz$ these events are force triggers where the RF trigger condition has not been met and are a reflection of the background conditions in which the TestBed was operating.
\item Calibration pulser events - these events contain signals from a number of calibration antennas placed around the TestBed to provide a source with which to asses reconstruction and analysis tools.

\end{itemize}

The RF triggered events recorded by the TestBed form the majority of the data set and are those to be analysed and assesed to see whether they contain neutrino induced signals. Minimum bias events were recorded at regular intervals by the DAQ system in order to provide a picture of the radio environment during the course of data taking. As they do not require a physics trigger condition these events are in the main thermal in nature. There are, however, periods for which repetative or long duration anthroprogenic noise sources are active contaminating this thermal sample of events.

During the course of data taking two calibration sources were active: a VPol calibration pulser in 2011, and a HPol calibration pulser in 2012. The pulsers were fired at a rate of $1 \hertz$ using the DAQ's GPS PPS as a trigger. The result is that these events are identifiable via trigger timing information and removed from the `$90 \%$ sample'. These calibration pulser events were used in training the reconstruction methods as well as a number of the cuts used in this analysis. Being the only contolled in ice source of impulsive radio signals calibration pulser events are used as a proxy for neutrino induced signals are provide an invaluable cross-check for any analysis tools and cuts.

The two data samples defined in the blinding strategy were comprised of a combination of the event types described above:

\begin{itemize}

\item `burn sample' - Sample of events intended for analysis tools and cut development. Comprised of all calibration events, all minimum bias events and $10 \%$ of RF triggered events.
\item `$90 \%$ sample' - The remaining $90 \%$ of RF triggered events.

\end{itemize}

A third sample of events consisting of simulated neutrino signals were produced using the official ARA simulation AraSim. This sample was produced with fixed incident neutrino energies in half decade intervals between $10^{17} \eV$ and $10^{21} \eV$ and was used to inform cuts and help with development of analysis tools such as source reconstruction. 

AraSim simulates neutrino signals in three stages: the neutrino propogation and interaction, RF signal transmission through the ice to the TestBed antennas and finally the output of the digitisation and triggering paths within the TestBed detector. The resulting data set contains digitised waveforms that would be expected to be recorded by the TestBed given knowledge of the TestBed detector and neutrino interactions. 

Neutrinos are produced with isotropic arrival directions within a uniform volume around the center of the TestBed. Each event is simulated independently and assigned a weight representing the probability that the neutrino would have reached the interaction point without being absorbed in the Earth. The shower development and RF Cherenkov emission are modeled before signals are propogated to the TestBed using a ray-tracing algorithm to determine the path taken through ice which, due to the changing index of refraction, leads to ray bending effects resulting in zero, one or two rays arriving at the antennas. Finally the signals are propogated through a model of the triggering and digitisation chains within the TestBed, which are based upon measurements taken in the laboratory ahead of installation in the ice.

In addition to simulating the expected neutrino signals thermal noise is added to the events. The noise model is derived from minimum bias events recorded in the TestBed and tuned to match the observed noise levels and trigger rates. 


\section{Event Reconstruction}
\label{sec:Analysis:Reconstruction}

Directional reconstruction of incident radio signals recorded in the TestBed is a powerful tool with which to identify and remove backgrounds, whilst providing invaluable information about possible neutrino events. Interferometric techniques have been successfully used in similar experiments, for example the ANITA experiment, that also record high fidelity radio waveforms. There are, however, a number of obstacles to robust reconstruction using interferometry in the TestBed. 

The small number of antennas (4 deep antennas in each polarisation) limit the measured strength of any preferred source direction, which would be re-inforced with more antennas. The varying index of refraction in the firn layer (typically extending $\sim 150 \meter$ into the ice close to the south pole) causes ray-bending effects that distort the true arrival direction. And finally the uncertainty in the deployed positions of the receive and calibration antennas in the ice can further complicate reconstruction. 


A new reconstruction method was developed for this analysis, based upon calculating timing offsets between waveforms that maximise correlation. This is achieved by creating a coherently summed wave (CSW) where individual antenna waveforms, scaled by the total number of waveforms, are added offset relative to one another. These offsets are calculated in a manner such that the correlation between the resulting CSW and the original waveforms is maximised, as measured by the normalised cross-correlation $C_{1,2}$:


\begin{equation}
  C_{1,2}(\Delta t) = \frac{\psi_{1} \star \psi_{2}}{\sigma_{1} \sigma_{2}}
  \label{eq:analysis:Reconstruction:Normalised-Cross-Correlation}
\end{equation}

\noindent where $\psi_{1/2}$ are the time domain waveforms, $\Delta t$ the time offset between them and $\sigma_{1/2}$ are the waveform's RMS. For discretely sampled waveforms containing a limited number of samples the cross-correlation $\psi_{1} \star \psi_{2}$ is given by:

\begin{equation}
  \psi_{1} \star \psi_{2} (\Delta t) = \sum_{n}^{N} V_{1}(t_{n}) V_{2}(t_{n}-\Delta t)
  \label{eq:analysis:Reconstruction:Discrete-Cross-Correlation}
\end{equation}

\noindent where the voltages $V_{1/2}$ outside of waveform window are taken to be zero. A simple algorithm is implemented to find the set of timing offsets that maximise the correlation between each waveform and the resulting CSW. The timing differences between pairs of antennas found using this method are shown in \FigureRef{fig:analysis:Reconstruction:CSW-DeltaT} for a selection of calibration pulser events a width of $\sim 150 \pico \second$. 

\begin{figure}[htpb]
  \subfloat[Antenna 1 and Antenna 2]{\includegraphics[width=0.49\textwidth]{chapters/analysis/DeltaT01-CP-VPol.pdf}}\hfill
  \subfloat[Antenna 1 and Antenna 3]{\includegraphics[width=0.49\textwidth]{chapters/analysis/DeltaT02-CP-VPol.pdf}}\\
  \subfloat[Antenna 1 and Antenna 4]{\includegraphics[width=0.49\textwidth]{chapters/analysis/DeltaT03-CP-VPol.pdf}}
  \caption{CSW measured time offsets between pairs of VPol antennas for calibration pulser events.}
  \label{fig:analysis:Reconstruction:CSW-DeltaT}
\end{figure}


The VPol calibration pulser signal, which was used during 2011, is a very bright source causing compression in some of the digitised waveforms and resulting in the main peak and side lobes being of a similar size. When the CSW is formed either the main peak or side lobes of the waveforms are lined up, leading to a double peak structure in the time difference between antenna's 1 and 3. In \FigureRef{fig:analysis:Reconstruction:CSW-Example} the calculated time differences are applied to offset individual waveforms, with the resulting CSW also shown for a calibration pulser event, noise event and simulated neutrino event. The CSWs formed in this manner differ significantly between thermal noise waveforms and signal type waveforms (i.e. the calibration pulser and simulated neutrino events). Two main features are apparent: firstly the size of the peak in the coherently summed wave is much greater for signal type events, and also the resulting CSW looks very similar to the shapes of the individual waveforms. Both of these properties of signal waveforms can be utilised in descriminating between these two categories of events in a neutrino search.


%



\begin{figure}[htpb]
  \subfloat[Individual waveforms calibration pulser event]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CSW-Coherent-Waveforms-VPol-CP-Wide.pdf}}\hfill
  \subfloat[CSW calibration pulser event]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CSW-CSW-VPol-CP-Wide.pdf}}\\
  \subfloat[Individual waveforms noise event]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CSW-Coherent-Waveforms-VPol-Noise-Wide.pdf}}\hfill
  \subfloat[CSW noise event]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CSW-CSW-VPol-Noise-Wide.pdf}}\\
  \subfloat[Simulated neutrino event]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CSW-Coherent-Waveforms-VPol-Nu-Wide.pdf}}\hfill
  \subfloat[Simulated neutrino event]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CSW-CSW-VPol-Nu-Wide.pdf}}
  \caption{(a) and (c) show individual antenna waveforms aligned in time. (b) and (c) show the resulting coherently summed wave.} 
  \label{fig:analysis:Reconstruction:CSW-Example}
\end{figure}


The timing difference between pairs of antennas holds information about the arrival direction of the radio signal and are checked against those calculated from a simple ice model. The model takes the index of refraction to be a constant, equal to the measured value at the average depth of the borehole antennas. A pseudo-$\chi^{2}$ is computed for a series of trial source locations in 1 degree bins in $\theta$, $\phi$ and logarithmically spaced bins in radial distance $R$:

\begin{equation}
  \mbox{pseudo-}\chi^{2} = \sum_{i} \frac{(\Delta t_{1,i}^{meas} - \Delta t_{1,i}^{exp})^{2}}{\sigma^{2}}
  \label{eq:analysis:Reconstruction:ChiSq}
\end{equation}


\noindent  where $\Delta t_{1,i}^{meas}$ is the measured offset between antenna $1$ and antenna $i$, $\Delta t_{1,i}^{exp}$ is the calculated offset expected from a trial source location and $\sigma$ is taken to be $1 \nano \second$ (which is similar to the timing uncertainty expected given uncertainty on the antenna positions). The reconstructed location is that which minimises pseudo-$\chi^{2}$ and hence corresponds to the most likely physical location given the measured time offsets. Calculating pseudo-$\chi^{2}$ values in all possible $\theta$, $\phi$ and $R$ bins is computationally intensive and a time consuming process, so an algorithm was developed to only search a subset and identify the best fit location.


 This method has the benefit of using the rich information contained within the digitised waveforms (correlation techniques result in precision of $\sim 150 \pico \second$ resolution in timing differences between pairs of antennas) as well as providing a parameter that describes the goodness of fit in pseudo-$\chi^2$ upon which a cut can be placed. As thermal signals will have random measured offsets between antennas the preferred source location will, in general, have a relatively large pseudo-$\chi^2$ value associated with it, thus a requirement for good reconstruction will additionally reject a large number of thermal events.

\begin{figure}[htpb]
  \subfloat[Pseudo-$\chi^{2}$ map of calibration pulser event]{\includegraphics[width=0.44\textwidth]{chapters/analysis/ChiSqMap-VPol-CP.pdf}}\hfill
  \subfloat[Pseudo-$\chi^{2}$ map of noise event]{\includegraphics[width=0.44\textwidth]{chapters/analysis/ChiSqMap-VPol-Noise.pdf}}\\
  \subfloat[Pseudo-$\chi^{2}$ map of simulated neutrino event]{\includegraphics[width=0.44\textwidth]{chapters/analysis/ChiSqMap-VPol-Nu.pdf}}
  \caption{Reconstruction maps of calculated pseudo-$\chi^{2}$ values for the same calibration pulser event in \FigureRef{fig:analysis:Reconstruction:CSW-Example}. The cricles in (a) and (c) indicate the true source location.}
  \label{fig:analysis:Reconstruction:CSW-ChiSq-Example}
\end{figure}

\FigureRef{fig:analysis:Reconstruction:CSW-ChiSq-Example} shows reconstruction maps for a series of event types, consisting of calculated pseudo-$\chi^{2}$ values for points on the surface of a sphere at the same radial distance as the best fit location. CSW reconstruction is attempted for each polarisation in every event, with the best fit location as well as corresponding pseudo-$\chi^{2}$ value recorded. \FigureRef{fig:analysis:Reconstructed:CSW-Residuals} shows the residuals (measured minus true) for azimuth and elevation angle for an ensamble of calibration pulser events and for neutrino events simulated with AraSim. Reconstruction of azimuth and elevation is $\sim 1^{\circ}$, although the ray-bending effects in the ice cause elevation angles to be systematically shifted. The ray-bending becomes more pronounced for sources at large radial distances from the TestBed and, as there is more target volume at these large distances, the majority of simulated neutrino events  suffer from these shifts. It is possible to calculate a transfer function to correct the shift in reconstructed elevation angle between true and reconstruction source location. This is an effective mapping between the ice models used for simulation of RF propogation in the ice and used in the reconstruction. The elevation residuals for simulated neutrino events in \FigureRef{fig:analysis:Reconstructed:CSW-Residuals} have such a correction applied and show that the systematic shift is succesfully removed.


\begin{figure}[htpb]
  \subfloat[Simulated neutrino reconstruction azimuth]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CSW-Reco-Residuals-Phi-Sim.pdf}}\hfill
  \subfloat[Simulated neutrino reconstruction elevation]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CSW-Reco-Residuals-Theta-Sim.pdf}}\\
  \subfloat[Calibration pulser reconstruction azimuth]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CSW-Reco-Residuals-Phi-CP.pdf}}\hfill
  \subfloat[Calibration pulser reconstruction elevation]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CSW-Reco-Residuals-Theta-CP.pdf}}\\
  \subfloat[Calibration pulser reconstruction azimuth]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CSW-Reco-Residuals-Phi-CP-HPol.pdf}}\hfill
  \subfloat[Calibration pulser reconstruction elevation]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CSW-Reco-Residuals-Theta-CP-HPol.pdf}}
  \caption{Residuals for reconstructed source direction azimuth ($\phi$) and elevation ($\theta$). For simulated neutrino events the source location is taken to be the neutrino interaction point. Due to ray-bending effects a correction factor is applied for simulated neutrino events to translate the reconstructed elevation angle to the line of sight to the source.}
  \label{fig:analysis:Reconstructed:CSW-Residuals}
\end{figure}

\section{Continuous Wave Removal}
\label{sec:Analysis:CWRemoval}

The frequency band for the TestBed contains a number of frequencies used for communications at the south pole. A particularly strong carrier signal used by the south pole station at $450 \mega \hertz$ is removed by a notch filter placed between the antenna output and low noise amplifiers downhole, but a number of other transmission frequencies remain unfiltered. Due to the TestBed's remote location and the relatively low levels of human activity (which are largely restricted to the summer season) CW signals are not present in the vast majority of RF triggers and minbias events. However, the presence of CW in an event can cause misreconstruction of the incident signal and, in some cases, mimic the properties that distinguish neutrino signals from thermal noise. For this reason these contaminated events constitute a background for any neutrino search, although the properties of such signals mean that it is possible to distinguish them from other interesting events. CW signals are characterised by large unthermal amplitudes in a small range of frequencies, compared with smaller broadband excesses in impulsive, neutrino-like, signals. This section will describe how the frequency content in the VPol and HPol antenna waveforms is used to identify such events and, as the fraction of these contaminated events is small, remove them from the analysis sample.

Prior to analysis of an event a thermal noise baseline is generated using minimum bias data, being the purest sample of thermal noise available for analysis. This baseline is taken to be a reflection of the thermal conditions in the TestBed during a run. The frequency content of an event can then be compared with this baseline to asses the level of un-thermal power and whether this power is confined to a small range of frequencies as expected from CW events.

\subsection{Thermal Noise Baselines}
\label{sec:Analysis:CWRemoval:Baselines}

The frequency domain amplitudes of thermal noise are Rayleigh distributed:

\begin{equation}
  \mbox{Rayleigh p.d.f.} = \frac{A}{\sigma^{2}}e^{\frac{-A^{2}}{2\sigma^{2}}}
  \label{eq:Analysis:CWRemoval:Rayleigh-pdf}
\end{equation}

\noindent where $A$ is the amplitude at frequency $f$ and $\sigma$ can be used to characterise the distribution. When creating a baseline for a run the fourier transform is taken of the time domain waveforms for each minimum bias event. The resulting frequency domain amplitudes are histogrammed per frequency bin per antenna and fitted with Rayleigh distributions.


\begin{figure}[htpb]
  \centering
  \includegraphics[width=\mediumfigwidth]{chapters/analysis/RayleighFit-VPol-Ant1-403.7MHz.pdf}
  \caption{Thermal noise amplitudes in VPol antenna 1 at 403.7 MHz for minimum bias data taken on 20th May 2011 (black) and a Rayleigh distribution fit to the data (red). The dashed black line is the same histogram but this time populated from a run containing a known CW source operating at $\sim 403 \mega \hertz$.}
  \label{fig:analysis:CWRemoval:Baselines:Rayleigh-Fit}
\end{figure}



\FigureRef{fig:analysis:CWRemoval:Baselines:Rayleigh-Fit} shows one such Rayleigh fit for the case of a run containing mainly thermal events, and for a run containing a fraction of CW contaminated events. For each run the $\sigma$ values, which are calculated per frequency range per antenna, are recorded as well as the average power per frequency per antenna. Some runs contain a fraction of CW events large enough to distort the Rayleigh distributions, making them unusable as a representation of the thermal conditions, and their baselines are rejected as `bad' (the dashed line in \FigureRef{fig:analysis:CWRemoval:Baselines:Rayleigh-Fit} shows such a run, the resulting Rayleigh fit would differ considerably from that derived from the solid line, event though these runs were taken on the same day). Due to the narrow band nature of CW signals it is possible to identify bad baselines by looking for spikes in the average power spectra shown in \FigureRef{fig:analysis:CWRemoval:Baselines:Averaged-Power}. These spikes are identified by looking for the second derivative of the average power spectrum falling below a threshold, indicating the presence of a spike. Any run that contains at least one borehole antenna with a spike in the average power spectrum is rejected. 

\begin{figure}[htpb]
  \subfloat[VPol Antennas]{\includegraphics[width=0.44\textwidth]{chapters/analysis/Rayleigh-Sigma-VPol.pdf}}\hfill
  \subfloat[HPol Antennas]{\includegraphics[width=0.44\textwidth]{chapters/analysis/Rayleigh-Sigma-HPol.pdf}}
  \caption{Rayleigh fit derived $\sigma$ values for two different baselines. The solid lines are for a baseline calculated from a thermal noise sample, and the dashed lines for a baseline containing a known CW source operating at $403 \mega \hertz$.} 
  \label{fig:analysis:CWRemoval:Baselines:Rayleigh-Sigma}
\end{figure}

The baselines calculated in this manner are used to summarise the thermal conditions of the TestBed, examples are shown in \FigureRef{fig:analysis:CWRemoval:Baselines:Rayleigh-Sigma}. The baseline that an event is compared to should therefore be chosen to be from a period with similar thermal conditions. In the main this will be the baseline calculated from the run in which the event was recorded, but where this baseline contains a large amount of CW contamination (hence the baseline is rejected) the closest run in time is used. The thermal conditions change slowly compared with the rate at which runs are taken, hence no scaling is needed to account for variations in the conditions.

\begin{figure}[htpb]
  \subfloat[VPol Antennas]{\includegraphics[width=0.49\textwidth]{chapters/analysis/Rayleigh-Power-VPol.pdf}}\hfill
  \subfloat[HPol Antennas]{\includegraphics[width=0.49\textwidth]{chapters/analysis/Rayleigh-Power-HPol.pdf}}
  \caption{Averaged power spectra for (solid lines) a run containing largely thermal events, and (dashed lines) a run containing a CW source. Bad runs, such as that summarised by the dashed lines, are identified by spikes in the averaged power spectra characterised by the second derivative falling below a threshold.}
  \label{fig:analysis:CWRemoval:Baselines:Averaged-Power}
\end{figure}


\subsection{Identifying CW Contaminated Events}
\label{sec:Analysis:CWRemoval:CW-Identification}

Each event has it's frequency content assessed to identify CW signals. Discrete fourier transforms are taken of each event's time domain waveforms. Using the Rayleigh distributions from the chosen baseline it is possible to asses the probability of the measured frequency domain amplitudes given the thermal distributions characterised by $\sigma$ in the baseline:

\begin{equation}
  P(A \geq A_{meas}) & = \int \limits_{A_{meas}}^{\infty}\frac{A}{\sigma^{2}}e^{\frac{-A^{2}}{2\sigma^{2}}}dA\\
  & = e^{\frac{-A_{meas}^{2}}{2\sigma^{2}}}
  \label{eq:Analysis:CWRemoval:Rayleigh-cdf}
\end{equation}

\noindent where $A_{meas}$ is the amplitude measured in a frequency interval for a particular antenna in the event being assessed. $P(A_{meas} \geq A)$ is then a measure of the probability of thermal fluctuations giving rise to the measured amplitude, and can be interperated as measuring how `un-thermal' that amplitude is. In order to push down the threshold CW signal size to which the filter is sensitive the product of probabilities for the borehole antennas is taken:

\begin{equation}
  P_{prod} = \prod P_{i} = \prod P(A \geq A_{i, meas})
  \label{eq:Analysis:CWRemoval:Prod-Prob}
\end{equation}

\noindent where $P_{prod}$ is calculated seperately for VPol and HPol antennas. Any frequency bins that have $P_{prod}$ less than a threshold, which is choosen to be such that 1 in $10^{6}$ thermal events will produce such a value, are considered to be in excess. 


\begin{figure}[htpb]
  \subfloat[Noise Waveform]{\includegraphics[width=0.49\textwidth]{chapters/analysis/Waveform-VPol-Ant2-Noise-Wide.pdf}}\hfill
  \subfloat[Noise Probability Spectrum]{\includegraphics[width=0.49\textwidth]{chapters/analysis/ProdProb-VPol-Noise-Wide.pdf}}\\
  \subfloat[CW Contaminated Waveform]{\includegraphics[width=0.49\textwidth]{chapters/analysis/Waveform-VPol-Ant2-WB-Wide.pdf}}\hfill
  \subfloat[CW Probability Spectrum]{\includegraphics[width=0.49\textwidth]{chapters/analysis/ProdProb-VPol-WB-Wide.pdf}}
  \caption{Example waveforms from VPol antenna 2 showing (a) thermal noise event and (b) a CW contaminated event.}
  \label{fig:analysis:CWRemoval:Baselines:Waveforms}
\end{figure}

Example waveforms from VPol antenna 2 are shown in \FigureRef{fig:analysis:CWRemoval:Baselines:Waveforms} for a thermal and CW contaminated event, along with the corresponding product of probabilities. The CW contaminted event is clearly identified by a narrow range of frequencies passing the threshold, information that can be used to reject the event. \FigureRef{fig:analysis:CWRemoval:Filtering:CW-Time} shows how this product of probabilities spectrum changes over the course of a run for calibration events and for non-calibration events. A weather balloon launch is clearly visible using these spectra resulting in a narrow range of frequencies exhibiting highly unthermal amplitudes in the VPol antennas, whereas calibration pulser events show a broadrange of frequencies with non-thermal amplitudes. 


\begin{figure}[htpb]
  \subfloat[Calibration Pulser Events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CW-Prob-Freq-Time-CP.eps}}\hfill
  \subfloat[Non Calibration Pulser Events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/CW-Prob-Freq-Time-NCP.eps}}
  \caption{The probability spectra for events averaged over 1 minute periods for (a) calibration pulser events (b) for non-calibration pulser events. A weather balloon launch at 23:20 is clearly visible as the turn on of a CW signal at $403 \mega \hertz$ in both figures. The calibration pulser events show a broad range of frequencies having excess power for the duration of the run.}
  \label{fig:analysis:CWRemoval:Filtering:CW-Time}
\end{figure}


Any CW removal must be able to reject contaminated events whilst at the same time passing broadband signals, such as the calibration pulser or simulated neutrinos. Two parameters are derived from an event's VPol (HPol) antennas: the total number of frequency bins (totalBins) that pass the threshold and are in excess, and the minimum value of $\ln(\prod P_{i})$ (minProb) from these frequency bins (i.e. the value that is least probable in the event). Events that contain CW contamination will have totalBins being a small, non-zero, number upon which a cut can be placed. 

In addition to the narrow range of frequencies exhibiting non-thermal power the size of these excesses can be used to identify particularly bright events. The power transmitted by a CW signal is confined to a single frequency leading to measured amplitudes much greater than those from broadband signals, where the power is spread over a range of frequencies. This means that a second cut can be placed on minProb, rejecting events where minProb is below a threshold and hence the measured amplitudes are far in excess of those expected from thermal noise. These parameters are illustrated in \FigureRef{fig:analysis:CWRemoval:Filtering:CW-MinProb-TotalBins} for calibration pulser and non-calibration pulser events taken from one month of burn sample data in 2011. Events are rejected when the total bins passing the thermal threshold is between 1 and 15, indicating that excess power is limited to a relatively narrow range of frequencies. A second cut is used to reject particularly bright CW events that cause power to leak into many frequency bins. This cut rejects events where minProb falls below a value of $-400$, a value safely removed from that produced by calibration pulser events. 


\begin{figure}[htpb]
  \subfloat[Non-calibration pulser events]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CW-minProb-totalBins-NCP.pdf}}\hfill
  \subfloat[Calibration pulser events]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CW-minProb-totalBins-CP.pdf}}\\
  \subfloat[Non-calibration pulser events - excluding weather balloon frequency range]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CW-minProb-totalBins-NCPNot403.pdf}}\hfill
  \subfloat[Calibration pulser events - excluding weather balloon frequency range]{\includegraphics[width=0.44\textwidth]{chapters/analysis/CW-minProb-totalBins-CPNot403.pdf}}
  \caption{CW parameters minProb (minimum value of $\ln(\prod P_{i})$ in probability spectra) and totalBins (total number of frequency bins that are indentied to have non-thermal amplitudes) are shown for calibration pulser and non-calibration pulser events. The top row shows these parameters for the full range of in band frequencies, and the bottom panel excludes a range of frequencies around $403 \mega \hertz$ which are used by the weather balloon. The large vertical tails in the top row are clearly due to the presence of CW signals from the weather balloon and are used to inform cuts on minProb and totalBins.}
  \label{fig:analysis:CWRemoval:Filtering:CW-MinProb-TotalBins}
\end{figure}


\section{Data Quality Cuts}
\label{sec:Analysis:Data-Quality-Cuts}

A number of data quality cuts were implemented to remove various types of corrupted events. Approximately 1 month of data from 2012 were effected by a digitiser operation issue which resulted in waveforms with fewer than the usual number of time domain samples. These events were not recoverable and were thrown away using a minimum number of samples cut.

Another class of corrupted events were ones that had been corrupted during data processing, resulting in voltage-time waveforms with samples that had their voltage values corrupted.

A final class of bad quality events had a systematic and unphysical ramp up of voltage common to all digitised channels. These events were removed via an algorithm that checked the validity of data from each digitiser's clock channel.


\section{Thermal Cuts}
\label{sec:Analysis:Thermal-Cuts}

The analysis of TestBed data aims to remove all thermal events with a small number of cuts derived from the CSW, and CSW reconstruction described in \SectionRef{sec:Analysis:Reconstruction}. As the expected number of candidate neutrino events is very small the cuts implemented must reject all thermal events with a high level of confidence, with the target number of thermal events passing cuts around $0.1$ in the full data sample.

The minimum bias data collected during during the analysis period was used as a sample of thermal events. Due to the periodic presence of CW contamination cuts were applied to the thermal sample to remove contaminated events as described in \SectionRef{sec:Analysis:CWRemoval}. 

\subsection{Pseudo-$\chi^{2}$ Cut}
\label{sec:Analysis:Thermal-Cuts:Pseudo-ChiSq}

For each event CSW reconstruction is performed using the VPol and HPol antennas' waveforms seperately. As described in \SectionRef{sec:Analysis:Reconstruction} a pseudo-$\chi^{2}$ value is calculated for the best fit source location during the reconstruction, and this value is used to measure the quality of reconstruction. The reconstruction in each polarisation is classified as `good' when the best fit pseudo-$\chi^{2}$ value is below a value of two, and the event's polarisation is passed.

\begin{figure}[htpb]
  \subfloat[VPol 2011]{\includegraphics[width=0.44\textwidth]{chapters/analysis/ChiSqVPol.pdf}}\hfill
  \subfloat[HPol 2012]{\includegraphics[width=0.44\textwidth]{chapters/analysis/ChiSqHPol.pdf}}
  \caption{Best fit pseudo-$\chi^{2}$ values for minimum bias, calibration and simulated neutrino events. Events are passed when the pseudo-$\chi^{2}$ falls below the chosen cut value of 2, marked by the orange arrow.}
  \label{fig:Analysis:Thermal-Cuts:Pseudo-ChiSq}
\end{figure}
  
\FigureRef{fig:Analysis:Thermal-Cuts:Pseudo-ChiSq} shows the pseudo-$\chi^{2}$ values for each polarisation for a sample of thermal, calibration pulser and simulated neutrino events. Only $\sim 10^{-7}$ calibration pulser events have a best bit pseudo-$\chi^{2}$ in the same polarisation greater than pseudo-$\chi^{2}=1$ which was used to inform the chosen cut value, passing events with pseudo-$\chi^{2} < 2$. 

\subsection{Powherence Cut}
\label{sec:Analysis:Thermal-Cuts:Powherence}

Along with being reconstructable neutrino events are expected to exhibit non-thermal levels of power and coherence between antennas, and can be used to seperate the two types of event. The peak absolute voltage in the CSW, named \textit{CSWPeakVoltage}, is used a measure of the power in the event. 

In order to measure the coherence between antennas a cross-correlation is taken between each antenna and the CSW minus that antenna:

\begin{equation}
  \mbox{CSW}(t) = \frac{1}{N}\sum_{i} \psi_{i}(t+\Delta t_{1,i})\\
  \mbox{CSW}_{N-1}^{j}(t) = \frac{1}{N-1}\sum_{j \neq i} \psi_{i}(t+\Delta t_{1,i})\\
  \mbox{C}_{N-1}^{j}(\Delta t) = {\mbox{CSW}_{N-1}^{j} \star \psi_{j}}
\end{equation}

\noindent where $\psi_{j}(t)$ is the time domain waveform of antenna $j$, CSW$_{N-1}^{j}(t)$ is the CSW minus antenna $j$ and C$_{N-1}^{j}(t)$ is the resulting cross-correlation waveform. For each cross-correlation waveform the maximum correlation value is taken and these values are summed to form a variable \textit{sumCorrVals}, which gives a measure of the correlation between antennas in the CSW.

The best discrimination between calibration pulser events (as a proxy for neutrino signals) and thermal noise events was found by taking a linear combination of CSWPeakVoltage and sumCorrVals. The resulting parameter, dubbed \textit{powherence}, should have low values for thermal events and high values for signal type events.


\begin{figure}[htpb]
  \subfloat[VPol 2011]{\includegraphics[width=0.44\textwidth]{chapters/analysis/PowHerenceVPol.pdf}}\hfill
  \subfloat[HPol 2012]{\includegraphics[width=0.44\textwidth]{chapters/analysis/PowHerenceHPol.pdf}}
  \caption{The composite parameter powherence is shown for a sample of thermal, calibration pulser and simulated neutrino events after the application of the pseudo-$\chi^{2}$ cut, along with the chosen cut value in orange. Events that have a $\mbox{powherence} > 380$ are passed as being signal like events.}
  \label{fig:Analysis:Thermal-Cuts:Powherence}
\end{figure}

In \FigureRef{fig:Analysis:Thermal-Cuts:Powherence} we see the powherence value calculated in each polarisation for the thermal data set alongside calibration pulser and simulated neutrino events. The relative brightness of the 2011 VPol calibration pulser can be seen clearly in the large values of powherence produced compared with the 2012 HPol calibration pulser.


\section{Anthroprogenic Cuts}
\label{sec:Analysis:Anthroprogenic-Cuts}

After applying thermal noise cuts the analysis sample should contain only signal-like events, however a large fraction (if not all) of these are expected to be associated with human activity and infrastructure at the south pole. These events are likely to be repetative both in reconstructed direction and in time, meaning they can be identified and removed by considering associated variables.

The first set of cuts are based on the CSW reconstructed source location and are referred to as \textit{Geometry Cuts}, the second set are to identify noisy periods within the analysis data set and are known as the \textit{GoodTimes} cuts.

\subsection{Geometry cuts}
\label{sec:Analysis:Anthroprogenic-Cuts:Geometry-Cuts}

The reconstructed locations of all VPol events passing thermal cuts are shown in \FigureRef{fig:Analysis:Anthroprogenic-Cuts:Geometry-Cuts:VPol-Reco} along with the positions of potential noise sources. A series of conservative geometry cuts are placed on an event's reconstructed source location designed to remove a large fraction of noise events:

\begin{itemize}

\item \textbf{Downward pointing cut} All events that reconstruct to elevation angles above $40^\circ$ are rejected

\item \textbf{South pole infrastructure cut} All events reconstructing within a $50^\circ$ wide region in azimuth associated with the IceCube laboratory and south pole station are rejected

\item \textbf{Calibration pulser cut} All events that reconstruct to within $5^\circ$ of any calibration pulser's azimuth are rejected

\item \textbf{Wind turbine cut} All events reconstructing to within $5^\circ$ of the wind turbine's azimuth are rejected.

\end{itemize}

\begin{figure}[htpb]
  \subfloat[VPol events passing thermal cuts]{\includegraphics[width=0.49\textwidth]{chapters/analysis/RecoVPol.pdf}}\hfill
  \subfloat[VPol events passing thermal cuts]{\includegraphics[width=0.49\textwidth]{chapters/analysis/TBGeometry.pdf}}
  \caption{he reconstructed azimuth and elevation angles are shown for all events passing CW and thermal cuts in (a) and the locations of various potential noise sources in (b). The shaded region in (b) indicates reconstructed directions that are rejected by geometry cuts.}
  \label{fig:Analysis:Anthroprogenic-Cuts:Geometry-Cuts:VPol-Reco}
\end{figure}

\subsection{Good times cut}
\label{sec:Analysis:Anthroprogenic-Cuts:Good-Times}
The final set of cuts termed `GoodTimes' criteria reject days of the year that have large numbers of non-thermal events in an attempt to remove repetative noise associated with human activity. The months of December and January are masked off, and all events within them rejected, as they correspond to the busiest periods of the summer season. Human activity is at its peak during these times involving frequent use of snow-mobiles, radio communication devices and a plethora of other potential noise sources. In order to identify other `noisy' periods of the year the sample of events passing thermal cuts are used to assess activity levels. The total number of events passing thermal cuts over a three day period is considered:

\begin{equation}
  N^{i}_{window} = N^{i-1} + N^{i} + N^{i+1}
\end{equation}

\noindent where $N^{i}$ is the number of non-thermal events from the $i^{th}$ day of the year. A day is masked off, and all non-thermal events from that day rejected, when $N^{i}_{window} > 14$. \FigureRef{fig:Analysis:Anthroprogenic-Cuts:GoodTimes:Event-Rate} shows the distribution of non-thermal events as a function of day of the year for both 2011 and 2012. For 2011 the numbers of non-thermal events significantly increase around the beginning and end of the year, with limited activity during the quiet austral winter. 2012, on the other hand, exhibits relatively few periods in which there are very few non-thermal events. This can, in part, be attributed to the TestBed operation being less closely monitered and managed during 2012.

\begin{figure}[htpb]
\subfloat[2011 non-thermal events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/GoodTimes2011.pdf}}\hfill
\subfloat[2012 non-thermal events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/GoodTimes2012.pdf}}
\caption{Shown in blue are the number of events per day passing thermal cuts and in red the subset of these events also passing geometry cuts.}
\label{fig:Analysis:Anthroprogenic-Cuts:GoodTimes:Event-Rate}
\end{figure}

\section{Cut results}
\label{sec:Analysis:Cut-Results}

The final analysis cuts and the result of their application to the analysis data sample are detailed in \TableRef{tab:Analysis:Cut-Flow} resulting in one VPol event passing all cuts, details of which are discussed in \SectionRef{chap:Results}. The thermal cuts, pseudo-$\chi^{2}$ and powherence, remove the majority of events illustrating that the main background in the TestBed is of a thermal origin. Continuous wave contaminated events appear to make up a large fraction of the remaining events, with daily weather balloon launches expected to contribute a significant number of events year round. 

\begin{table}
  \begin{center}
    \begin{tabular}{ c || c | c | c }
      Total & \multicolumn{3}{c}{ $4.84 \times 10^{8}$}\\
      \hline
      Cut & \multicolumn{3}{c}{ Number passing either polarisation}\\      
      \hline
      Data Quality & \multicolumn{3}{c}{$4.07 \times 10^8$}\\
      pseudo-$\chi^{2}$ & \multicolumn{3}{c}{$8.05 \times 10^7$}\\
      \hline\hline
      & \multicolumn{3}{c}{VPol}\\
      \hline
      cut & passing in order & rejected if last cut & rejected if first cut \\
      \hline
      pseudo-$\chi^{2}$ & $3.74 \times 10^7$ & 0 & 0\\
      powherence & $1.57 \times 10^6$ & $4.31 \times 10^6$ & $3.58 \times 10^7$\\
      CW - totalBins & $9.66 \times 10^5$ & $1.66 \times 10^3$ & $1.07 \times 10^7$\\
      CW - minProb & $5.76 \times 10^5$ & 710 & $7.27 \times 10^5$\\
      Geometry & $9.75 \times 10^3$ & 340 & $2.54 \times 10^7$\\
      GoodTimes & $1$ & $9.75 \times 10^3$ & $2.51 \times 10^7$\\
      \hline\hline
      & \multicolumn{3}{c}{HPol}\\
      \hline
      cut & passing in order & rejected if last cut & rejected if first cut \\
      \hline
      pseudo-$\chi^{2}$ & $4.32 \times 10^7$ & 0 & 0\\
      powherence & $5.74 \times 10^5$ & $6.25 \times 10^6$ & $4.26 \times 10^7$\\
      CW - totalBins & $4.21 \times 10^5$ & 456 & $9.67 \times 10^6$\\
      CW - minProb & $2.97 \times 10^5$ & 331 & $2.44 \times 10^5$\\
      Geometry & $1.42 \times 10^4$ & 116 & $2.64 \times 10^7$\\
      GoodTimes & $0$ & $1.42 \times 10^4$ & $2.84 \times 10^7$\\      
      \end{tabular} 
    \caption{Analysis cuts appled to the `$90 \%$ sample'.}
    \label{tab:Analysis:Cut-Flow}
  \end{center}
\end{table}

In order to asses whether any passing events are a statistically significant observation of a neutrino flux it is necessary to asses two important factors: firstly the efficiency of detecting simulated neutrinos using these cuts and secondly an estimation of the expected number of background events. The background estimation is discussed in \SectionRef{sec:Analysis:Background-Estimation}, and the analysis efficiency is calculated using the sample of simulated neutrino events using AraSim.

The analysis passing efficiency is shown in \FigureRef{fig:Analysis:Cut-Results:Efficiency} as a function of neutrino energy and also signal to noise ratio (SNR), which is taken calculated as follows:

\begin{equation}
  \mbox{SNR} = \frac{\lvert V_{peak} \rvert}{\mbox{RMS}}
\end{equation}

\noindent where $\lvert V_{peak} \rvert$ is the absolute value of the peak voltage of each waveform. SNR values are calculated for all antennas and the smallest value in each polarisation compared, the larger of the two is then used as a measure of signal strength (as the RF impulse in events can have an arbitrary polarisation angle, so the brighter of the two polarisations is used).

The efficiencies in \FigureRef{sec:Analysis:Background-Estimation} are calculated for application of cuts individually (dashed lines) and for all cuts applied. The good times cut is not accounted for as it acts as a scaling of the detector live time. The overall analysis efficiency ranges between $20 \%$ and $30 \%$ accross the range of energies tested, whereas it peaks at $60 \%$ for moderately large values of SNR. Two factors influence the low efficiency as a function of neutrino energy: firstly the simulation produces large numbers of events with very small SNR which mainly consist of upward fluctuations in the thermal noise, and secondly compression in the digitisation chain leads to a drop off in efficiency at high SNR. 

The drop off in efficiency at high SNR is driven by very large amplitudes frequency domain amplitudes being produced when big signals are propogated through the signal chain. As a result the CW minProb cut removes a large fraction of these very bright events. 


\begin{figure}[htpb]
\subfloat[Analysis efficiency as a function of neutrino energy]{\includegraphics[width=0.49\textwidth]{chapters/analysis/efficiencyEnergy.pdf}}\hfill
\subfloat[Analysis efficiency as a function of SNR]{\includegraphics[width=0.49\textwidth]{chapters/analysis/efficiencySNR.pdf}}
\caption{Analysis efficiency for simulated neutrino events. The solid black line shows the efficiency after applying all cuts and the dashed lines show efficiencies for individually applied cuts.}
\label{fig:Analysis:Cut-Results:Efficiency}
\end{figure}


\section{Background estimation}
\label{sec:Analysis:Background-Estimation}

Due to the differences in signal type it is necessary to estimate backgrounds seperately for thermal noise and anthroprogenic events. In order to estimate the expected number of events that pass all events the distributions for events failing particular cuts, specific to signal type, were considered and extrapolated from fits to data.

For thermal noise events the value of powherence was considered the most relevant parameter and proved to follow closely an exponentially falling distribution. Two samples of events passing all but the powherence cuts were assesed: the first being all minimum bias events and the second all RF triggered events, in both cases pseudo-$\chi^{2}$ and anthroprogenic cuts are applied. The former sample of events is the purest sample of thermal noise since no trigger condition is met for these events, however a scaling must be applied when accounting for the increase in statistics between this data set and the full set of RF triggers. The distribution of powherence in VPol and HPol and fits to the falling edge approaching the cut value are shown in \FigureRef{fig:Analysis:Background-Estimation:Thermal-Background} for the minimum bias sample. 

\begin{figure}[htpb]
\subfloat[VPol minimum bias events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/PowHerenceFitVPol.pdf}}\hfill
\subfloat[HPol minimum bias events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/PowHerenceFitHPol.pdf}}
\caption{Thermal noise sample taken from the minimum bias data set is fitted to an exponential function for VPol and HPol events. This is then used to extrapolate beyond the chosen cut value (orange line) to estimate the expected number of thermal events passing the cut in the analysis data sample.}
\label{fig:Analysis:Background-Estimation:Thermal-Background}
\end{figure}

Extrapolating the fits to each of the thermal samples of events provides two estimates for the number of events passing the powherence cut and errors associated with the fits themselves. Since fits to both samples were in good agreement to data the lower of the two predictions was taken as the background expectation and the error to represent the range of values. The result is an expected number of background events of a thermal origin to be $0.18^{+0.30}_{-0.18}$.

For the case of anthroprogenic signals it is much more difficult to ascertain the expected background levels since these events are from an unidentified mixture of sources, which are not necessarily expected to follow well described distributions. An estimate was made by considering the events that failed the CW minProb cut as the last cut applied to VPol events. This selection of events should be composed of anthroprogenic signals that contain some level of CW contamination which are distributed up to the cut threshold of -400 described in \SectionRef{sec:Analysis:CWRemoval}. 

The tail adjacent to the cut value was fitted with a gaussian as shown in \FigureRef{fig:Analysis:Background-Estimation:CW-Background} which is sensitive to both the binning and range of values that are considered in the fit. This approach had some success for VPol events, but when considering HPol events the low statistics severly limits the ability to fit any distribution. As a result the fit to VPol events, scaled by the relative change in statistics, is used as an estimate for HPol events.

A number of different fits were made resulting in a range of predicted backgrounds. A conservative approach was taken in estimating the expected background levels and the fit shown results in a lower number of expected background events than other estimates made. The range of values predicted is accounted for in the final estimation, being $0.20^{+0.84}_{-0.20}$. When both types of backgrounds are considered together the single VPol event that passes all analysis cuts should be compared with a background of $0.38^{+0.89}_{-0.38}$.


\begin{figure}[htpb]
\subfloat[VPol anthroprogenic events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/MinProbFitVPol.pdf}}\hfill
\subfloat[HPol anthroprogenic events]{\includegraphics[width=0.49\textwidth]{chapters/analysis/MinProbFitHPol.pdf}}
\caption{VPol (HPol) events from the analysis sample failing CW minimum probability as the last cut are shown along with a gaussian fit to the falling edge of the VPol events. This fit is used to estimate the number of expected anthroprogenic background events in analysis sample.}
\label{fig:Analysis:Background-Estimation:CW-Background}
\end{figure}
